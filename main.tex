% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Define Article %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\documentclass{article}
\input{header}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Using Packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{empheq}
\usepackage{mdframed}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{color}
\usepackage{psfrag}
\usepackage{pgfplots}
\usepackage{bm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Other Settings for spanish
%\renewcommand{\abstractname}{Resumen}
%\renewcommand{\figurename}{Figura}
%\renewcommand\refname{Referencias}

%%%%%%%%%%%%%%%%%%%%%%%%%% Page Setting %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\geometry{a4paper}

%%%%%%%%%%%%%%%%%%%%%%%%%% Define some useful colors %%%%%%%%%%%%%%%%%%%%%%%%%%
\definecolor{ocre}{RGB}{243,102,25}
\definecolor{mygray}{RGB}{243,243,244}
\definecolor{deepGreen}{RGB}{26,111,0}
\definecolor{shallowGreen}{RGB}{235,255,255}
\definecolor{deepBlue}{RGB}{61,124,222}
\definecolor{shallowBlue}{RGB}{235,249,255}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%% Define an orangebox command %%%%%%%%%%%%%%%%%%%%%%%%
\newcommand\orangebox[1]{\fcolorbox{ocre}{mygray}{\hspace{1em}#1\hspace{1em}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%% English Environments %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheoremstyle{mytheoremstyle}{3pt}{3pt}{\normalfont}{0cm}{\rmfamily\bfseries}{}{1em}{{\color{black}\thmname{#1}~\thmnumber{#2}}\thmnote{\,--\,#3}}
\newtheoremstyle{myproblemstyle}{3pt}{3pt}{\normalfont}{0cm}{\rmfamily\bfseries}{}{1em}{{\color{black}\thmname{#1}~\thmnumber{#2}}\thmnote{\,--\,#3}}
\theoremstyle{mytheoremstyle}
\newmdtheoremenv[linewidth=1pt,backgroundcolor=shallowGreen,linecolor=deepGreen,leftmargin=0pt,innerleftmargin=20pt,innerrightmargin=20pt,]{theorem}{Theorem}[section]
\theoremstyle{mytheoremstyle}
\newmdtheoremenv[linewidth=1pt,backgroundcolor=shallowBlue,linecolor=deepBlue,leftmargin=0pt,innerleftmargin=20pt,innerrightmargin=20pt,]{definition}{Definition}[section]
\theoremstyle{myproblemstyle}
\newmdtheoremenv[linecolor=black,leftmargin=0pt,innerleftmargin=10pt,innerrightmargin=10pt,]{problem}{Problem}[section]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Plotting Settings %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepgfplotslibrary{colorbrewer}
\usepackage{comment}
\usepackage{graphicx}
\usepackage{tcolorbox}
\usepackage{listings}
\usepackage{subcaption}
\usepackage{multicol}
\usepackage{siunitx}
\usepackage{float}
\usepackage{hyperref}
%\usepackage[english,spanish]{babel}
\usepackage[affil-it]{authblk}
\usepackage{bm}
\usepackage{lipsum}
\pgfplotsset{width=8cm,compat=1.9}
\captionsetup{subrefformat=parens}
\graphicspath{{images/}}
\newcommand{\quotes}[1]{``#1''}
\pdfcompresslevel=9  % Maximum compression
\pdfobjcompresslevel=3  % Reduce embedded objects
\pdfminorversion=4  % Reduce PDF version for compatibility
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Title & Author %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Monte Carlo Simulations}
\author{Jerónimo Noé Acito Pino}
\affil{Facultad de Matemática, Astronomía, Física y Computación\\ Universidad Nacional de Córdoba}
\date{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle
\begin{abstract}
    This work presents a series of Monte Carlo simulations implemented in Fortran to explore foundational concepts in statistical mechanics and numerical integration. The simulations include random walks in two and three dimensions, numerical integration using the rejection method and uniform sampling, inverse cumulative distribution function (CDF) sampling, and statistical validation of the Law of Large Numbers. For all cases, statistical indicators such as mean displacement, efficiency, distribution histograms, and convergence behavior were analyzed. The simulations confirm expected theoretical predictions, including the Gaussian behavior of random walks and convergence of integration error with $\frac{1}{\sqrt{N}}$. All code is modular, open-source, and designed for clarity and reproducibility.
\end{abstract}

\section{Introduction}
Monte Carlo methods are a class of computational algorithms that rely on repeated random sampling to obtain numerical results. Their flexibility makes them particularly suitable for tackling problems involving stochastic processes, high-dimensional integrals, and statistical distributions. Since their development in the mid-20th century, these methods have become indispensable across physics, finance, engineering, and other disciplines.

In this work, we implement several fundamental Monte Carlo simulations using Fortran. These include random walks in two and three dimensions to study diffusive behavior, numerical integration via the rejection sampling method, non-uniformly distributed random numbers via the inverse transform method, statistical convergence demonstrations via the Law of Large Numbers, and uniform-sampling-based Monte Carlo integration. Each program has been written in a modular fashion with clearly defined inputs, making it straightforward to modify or extend. Our aim is to both visualize and validate theoretical predictions through simulation, offering insight into the power and simplicity of Monte Carlo approaches.

Firstly, section \ref{subection:random_walk} deals with random walks as a succession of independent steps of length 1. Many walkers are simulated and relevant physical quantities (mean displacement and mean quadratic displacement) are calculated for the specified number of steps, averaging over all the walkers' trajectories. The program is general enough to calculate random walks in N dimensions, and individual trajectories can be saved for later analysis.

Section \ref{subection:rejections_method} showcases the rejection method. To this effect the bounds of a rectangle are specified and the program calculate the integral for the function specified. The program considers the positivity of the function to get the positive and negative accepted trials (above and below the x axis respectively), then subtract and scale them to get the integral. The sum, on the other hand, is used to calculate the efficiency of this method.

In the section \ref{subection:inverse_CDF}, we utilize the inverse cumulative distribution function (CDF) method to generate random numbers with a given point density function (PDF). To this effect, we integrate numerically the chosen PDF to get the CDF, invert it numerically (by array indexing). Then, by selecting random numbers from a uniform distribution, and using the calculated inverse of the CDF, we generate randomly distributed numbers obeying the chosen PDF.

Section \ref{subection:law_of_large_numbers} presents a simple method to illustrate a particular case of the Law of Large Numbers. The sum of N independent random numbers sampled from a uniform distribution is calculated and multiplied by $\frac{1}{N}$ in order to get a resulting number between 0 and 1. The distributions' moments and histograms are analysed, this last one with the aid of a short video.

Lastly, Monte Carlo integration is analysed in section \ref{subection:uniform_sampling_integration}. The sampling is performed over a uniform distribution and the error of the method investigated.

\section{Computational Details and Data Analysis}

All programs were made in Fortran, compiled with gfortran, and computed on a computer with Intel Core i5-9300H CPU @ 2.40GHz. The programs and modules used are available on github: \href{https://github.com/MrMxyzptlk-jpg/Monte-Carlo-Simulations.git}{https://github.com/MrMxyzptlk-jpg/Monte-Carlo-Simulations.git}

All programs are made with the same structure: a main program, a \quotes{modulos} directory containing all the relevant modules, an \quotes{input.nml} file and a \quotes{compile.sh}. The \quotes{compile.sh} file contains the order of modules compilations and the flags used. The calculation's variables for each program are contained in the \quotes{input.nml} file. All programs use double precision defined in the \quotes{modulos/presicion.f90} module. All output files are created in a \quotes{datos} directory which needs to be created if not already present. For the random number generator we have used the RNG implemented by  Marsaglia and Zaman\cite{MZ-paper}.

\subsection{Random Walks}
\label{subection:random_walk}

For the random walks we initialized $10^5$ different random walks, which take steps in each direction randomly, of length 1, all independent of the others. The mean displacement and mean quadratic displacement are calculated. The program allows for the specification of the minimum and maximum number of steps taken, thus the aforementioned quantities are calculated for each number of steps allowed. Finally, the trajectories of 20 random walkers are saved for later plotting. All calculations were done in 2D and 3D. A sample \quotes{input.nml} file is shown below.

    \begin{tcolorbox}[
        boxrule=0pt,
        sharp corners
    ]
        \begin{lstlisting}
        &calculation
            dim       = 2,
            walkers   = 100000,
            min_steps = 1,
            max_steps = 100,
            walkers_saved = 20,
            save_walks = .true.
        /
        \end{lstlisting}
    \end{tcolorbox}

The results are plotted in Figure \ref{fig:random_walk}. The paths taken by the walkers appear intuitively random and the mean displacement in 2D and 3D are close to 0, as expected. The standard deviation in both cases also follows the theoretical prediction $\sim \sqrt{d\cdot N}$ for d dimensions. For a more interesting analysis, we have made videos of these calculations, with QR codes in the appendix \ref{appendix:video}. The QR code in Figure \ref{fig_qr:random_walk_histogram} links to a video of the distribution of the final positions of the walkers as a function of the steps, for the 2D random walk. The QR codes in Figure \ref{fig_qr:random_walk_evolution} and Figure \ref{fig_qr:random_walk_paths} link to videos of the evolution of 20 walkers in 3D and the paths traced respectively. From the first video we see the distribution of the random walks tends to a gaussian distribution, which widens when the number of allowed steps increases, as predicted by Einstein in 1905 \cite{Einstein_random-walk}. In the other two videos we see that the walkers behave like particles in a gas, diffusing with time and with random paths.

    \begin{figure}[H]
        \centering
        \begin{subfigure}[t]{0.48\textwidth}
            \includegraphics[width=\textwidth]{random_walk/trajectories_2D.png}
            \caption{Path taken by 20 random walkers in 2D.}
        \end{subfigure}
        \begin{subfigure}[t]{0.48\textwidth}
            \includegraphics[width=\linewidth]{random_walk/trajectories_3D.png}
            \caption{Path taken by 20 random walkers in 3D (same color indexing as for the 2D case).}
        \end{subfigure}
        \\
        \begin{subfigure}[t]{0.48\textwidth}
            \includegraphics[width=\linewidth]{random_walk/mean_vs_steps.png}
            \caption{Mean displacements for the 2D and 3D random walks.}
        \end{subfigure}
        \begin{subfigure}[t]{0.48\textwidth}
            \includegraphics[width=\textwidth]{random_walk/stddev_vs_steps.png}
            \caption{Standard deviations (stddev) for the 2D and 3D random walks compared to the theoretical values.}
        \end{subfigure}
        \caption{Random walks in 2D and 3D.}
        \label{fig:random_walk}
    \end{figure}

\subsection{Rejection Method}
\label{subection:rejections_method}

For the integration we have selected $10^5$ Monte Carlo samples and a simple function $f(x) = sin(x) + cos(x)$ defined in a \quotes{funciones} module. The box in which the sampling is carried out is defined in the input file, with care that the y bounds enclose the function. For the y bounds we have chosen [0,2] and [-2,2], while for the integration limits (x bounds) we chose [0,1] and [0,10] respectively. A sample \quotes{input.nml} file is shown below:

    \begin{tcolorbox}[
        boxrule=0pt,
        sharp corners
    ]
        \begin{lstlisting}
        &calculation
            x_lowerLim = 0,
            x_upperLim = 1,
            y_lowerLim = -2,
            y_upperLim = 2,
            samples    = 100000
        /
        \end{lstlisting}
    \end{tcolorbox}

    The integrations' results are shown in Table \ref{tab:rejection_method} while the histograms created by the rejection method are displayed in Figure \ref{fig:rejections_method}. The rejection method has an efficiency ($efficiency = \frac{accepted}{rejected}$) around 0.3 and 0.2 for each integration, and the absolute error of the method is less for the integration with a higher success rate.

    \begin{table}[!h]
        \centering
        \begin{tabular}{|c|c|c|c|c|}\hline
        Bounds  &   MC integral     &   analytic integral   &   Abs error   &   Efficiency  \\\hline
        [0,1]   &   1.303920        &   1.301169            &   0.002751    &   0.3259800   \\\hline
        [0,10]  &   1.359600        &   1.295050            &   0.064549    &   0.23075     \\\hline
        \end{tabular}
        \caption{Table of the results for the rejection method integration.}
        \label{tab:rejection_method}
    \end{table}


    \begin{figure}[H]
        \centering
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\textwidth]{rejection_method/histogram_0-1.png}
            \caption{}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{rejection_method/histogram_0-10.png}
            \caption{}
        \end{subfigure}
        \caption{Histograms generated by the rejection method.}
        \label{fig:rejections_method}
    \end{figure}

\subsection{Inverse Cumulative Distribution Function (CDF) method}
\label{subection:inverse_CDF}

The program is able to generate random numbers for a distribution with PDF of the form $P(x) = (k+1)\cdot x^k$. The exponent is specified in the input file and was chosen to be $k = 3$. Furthermore, the integration of this function is done using the trapezium method (the number of points also specified in the input file) so as to get the CDF. Finally, a $10^5$ random numbers are generated from the inversion of the CDF. A sample \quotes{input.nml} file is shown below:

    \begin{tcolorbox}[
        boxrule=0pt,
        sharp corners
    ]
        \begin{lstlisting}
        &calculation
            exponent    = 3,
            Integration_points  = 1000,
            MC_samples = 100000
        /
        \end{lstlisting}
    \end{tcolorbox}

    The resulting random numbers generated with this program are plotted in Figure \ref{fig:inverse_CDF}, as well as the original PDF for comparison. Excellent agreement with the expected distribution is obtained using this method.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.48\linewidth]{inverse_CDF_method/MC_PDF.png}
        \caption{Monte Carlo generated random numbers (red dots) compared to the analytical PDF.}
        \label{fig:inverse_CDF}
    \end{figure}

\subsection{The Law of Large Numbers}
\label{subection:law_of_large_numbers}

For the summation we have selected $N$ variables ranging from 1 to 10 in steps of 1, and a sample size of $10^5$ chosen for each N. A sample \quotes{input.nml} file is shown below:

    \begin{tcolorbox}[
        boxrule=0pt,
        sharp corners
    ]
        \begin{lstlisting}
        &calculation
            N_variables = 100,
            samples = 100000
        /
        \end{lstlisting}
    \end{tcolorbox}

    The 4 first moments of the distributions generated are shown in Figure \ref{fig:law_of_large_numbers}. As expected, the mean and skewness oscillate around $\frac{1}{2}$ and 0 respectively, while the variance and kurtosis tend to 0. This results show that the distribution tends to concentrate around $\frac{1}{2}$ due to the way we summed the variables ($X = \frac{\sum_{i=1}^{N} x_i}{N}$). This process seems to create a Dirac-delta-like distribution, at least from the behaviour of the calculated moments.

    A clearer picture of the problem is obtained by generating a histogram of the resulting distribution. To this end we have created a video of the resulting distributions for each N, the link of which is in Figure \ref{fig_qr:law_of_large_numbers} of the appendix \ref{appendix:video}. From this video we see that the initial distribution is indeed uniform. Then, for N=2 we get a triangular distribution, as theory would predict. After this point, as N grows, the resulting distributions approximate a gaussian distribution. This is a visual representation of the Law of Large Numbers, for the particular case with the random variables following a uniform distribution.


    \begin{figure}[H]
        \centering
        \begin{subfigure}[t]{0.48\textwidth}
            \includegraphics[width=\textwidth]{law_of_large_numbers/mean.png}
            \caption{}
        \end{subfigure}
        \begin{subfigure}[t]{0.48\textwidth}
            \includegraphics[width=\linewidth]{law_of_large_numbers/variance.png}
            \caption{}
        \end{subfigure}
        \\
        \begin{subfigure}[t]{0.48\textwidth}
            \includegraphics[width=\linewidth]{law_of_large_numbers/skewness.png}
            \caption{}
        \end{subfigure}
        \begin{subfigure}[t]{0.48\textwidth}
            \includegraphics[width=\textwidth]{law_of_large_numbers/kurtosis.png}
            \caption{}
        \end{subfigure}
        \caption{Plots of the 4 first moments of the generated distributions of the sum of N uniformly distributed random variables.}
        \label{fig:law_of_large_numbers}
    \end{figure}

\subsection{Monte Carlo Integration (uniform sampling)}
\label{subection:uniform_sampling_integration}

For the integration we have selected $N$ Monte Carlo samples ranging from 10 to $10^5$ in steps of 10. A simple function $f(x) = x^k$ defined in a \quotes{funciones} module is chosen as the integrand. The integration limits chosen were [0,1], and the exponent set to $k = 4$. A sample \quotes{input.nml} file is shown below:

    \begin{tcolorbox}[
        boxrule=0pt,
        sharp corners
    ]
        \begin{lstlisting}
        &calculation
            exponent    = 4,
            lower_lim   = 0,
            upper_lim   = 1,
            max_sample_exponent = 10000
        /
        \end{lstlisting}
    \end{tcolorbox}

    The results were compared to the analytic solutions and the measures of error were plotted in Figure \ref{fig:MC_integration}. The theory predicts that the Monte Carlo integration error is of order $\mathcal{O}(\frac{1}{\sqrt{N}})$ where N is the sample size. We see that this value is an upper bound for the absolute error and the standard deviation ($\sigma _I$), but represents the most likely outcome for the relative error. We also see that there is a noticeable variation of the error for the absolute and relative cases (which only differ by a factor of the magnitude of the analytic integral) whilst there is a clear linear trend for the standard deviation. This is due to the fact that the measure of error for MC integration is $\sigma _I = \frac{V}{\sqrt{N}}\sigma _f $ where f is the PDF of the random numbers used. Given that the sampling was done over a uniform distribution, with variance $\frac{1}{12}$ we end up with an estimation of error for the MC integration of $\sigma _I = \frac{V}{\sqrt{12\cdot N}}$. This is in good agreement with the simulations run.

    \begin{figure}[H]
        \centering
        \begin{subfigure}{0.3\textwidth}
            \includegraphics[width=\textwidth]{Monte_Carlo_integration/MC_abs_error.png}
            \caption{Absolute error vs. sampling nuber (N).}
        \end{subfigure}
        \begin{subfigure}{0.3\textwidth}
            \includegraphics[width=\linewidth]{Monte_Carlo_integration/MC_rel_error.png}
            \caption{Relative error vs. sampling nuber (N).}
        \end{subfigure}
        \begin{subfigure}{0.3\textwidth}
            \includegraphics[width=\linewidth]{Monte_Carlo_integration/MC_stddev.png}
            \caption{Standard deviation ($\sigma$) vs. sampling nuber (N).}
        \end{subfigure}
        \caption{}
        \label{fig:MC_integration}
    \end{figure}



\bibliographystyle{unsrt}
\bibliography{refs}


\clearpage % Ensure figures before appendix are placed correctly
\appendix

\section*{Apéndice}
\phantomsection  % Creates a target for hyperlinks
\renewcommand{\thesection}{A\arabic{subsection}} % Ensures appendix sections are labeled as A1, A2, etc.
\addcontentsline{toc}{section}{Apéndice}  % Adds it to the table of contents


\subsection{QR codes for videos}
    \label{appendix:video}

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.45\textwidth]{random_walk/histogram_qrcode.png}
        \caption{QR code for 2D random walk histogram as a function of time.}
        \label{fig_qr:random_walk_histogram}
    \end{figure}

    \begin{figure}[H]
        \centering
        \begin{subfigure}{0.45\textwidth}
            \includegraphics[width=\textwidth]{random_walk/diffusion_evolution_qr.png}
            \caption{QR code for particles' diffusion by 3D random walk.}
            \label{fig_qr:random_walk_evolution}
        \end{subfigure}
        \hfill
        \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{random_walk/diffusion_paths_qr.png}
        \caption{QR code for particles' path during the diffusion by 3D random walk.}
        \label{fig_qr:random_walk_paths}
        \end{subfigure}
        \caption{}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.45\textwidth]{law_of_large_numbers/histogram_qrcode.png}
        \caption{QR code for histogram of the distributions generated by sum of random variables (Law of Large Numbers).}
        \label{fig_qr:law_of_large_numbers}
    \end{figure}

\end{document}